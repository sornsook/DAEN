{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Backward-network_testing.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"waS4IR-AwjLB","colab_type":"code","outputId":"e15b1908-32c4-4142-c00e-058032d1478b","executionInfo":{"status":"ok","timestamp":1574211439495,"user_tz":-420,"elapsed":112141,"user":{"displayName":"Sorn Sooksatra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDUB_44rDDjCoZMpsNP2bhyLr-lne4dcduqp2V75g=s64","userId":"02017460555029665816"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# %cd content\n","!ls\n","from google.colab import drive\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["sample_data\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LofZUTBTwsBe","colab_type":"code","outputId":"d56ec672-3ed1-4b1e-c9ee-b718cdb18026","executionInfo":{"status":"ok","timestamp":1574211447540,"user_tz":-420,"elapsed":6182,"user":{"displayName":"Sorn Sooksatra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDUB_44rDDjCoZMpsNP2bhyLr-lne4dcduqp2V75g=s64","userId":"02017460555029665816"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["%ls\n","%cd drive\n","%cd My Drive\n","%cd Crowding_project"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n","/content/drive\n","/content/drive/My Drive\n","/content/drive/My Drive/Crowding_project\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bKlg7-QPpriZ","colab_type":"text"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"aJ0plm7Epuwt","colab_type":"code","outputId":"a9b57173-181b-4002-c502-89fb79547689","executionInfo":{"status":"ok","timestamp":1574211582880,"user_tz":-420,"elapsed":3326,"user":{"displayName":"Sorn Sooksatra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDUB_44rDDjCoZMpsNP2bhyLr-lne4dcduqp2V75g=s64","userId":"02017460555029665816"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Input,Flatten, Conv2D, MaxPooling2D,UpSampling2D,add, concatenate\n","from keras.layers.convolutional import Convolution2D\n","from keras.layers.core import Dropout, Activation\n","from keras.layers.pooling import GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras import optimizers\n","\n","\n","# For imshow the images\n","import matplotlib\n","matplotlib.use('agg')\n","import matplotlib.pyplot as plt"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"N8BaP4KIpZ_2","colab_type":"text"},"source":["# Preparing the dataset "]},{"cell_type":"code","metadata":{"id":"YQhzPVQwpfCb","colab_type":"code","outputId":"c9e43e7e-4228-4f2c-efe7-92cddc6d2f1d","executionInfo":{"status":"ok","timestamp":1574211708542,"user_tz":-420,"elapsed":121038,"user":{"displayName":"Sorn Sooksatra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDUB_44rDDjCoZMpsNP2bhyLr-lne4dcduqp2V75g=s64","userId":"02017460555029665816"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#######################################################\n","# Import training input\n","train_images = np.load('Npy_data/Train_image.npy')\n","train_labels = np.load('Npy_data/Train_den.npy')\n","print('training preparation is completed')\n","\n","#######################################################\n","# Import validation input\n","val_images = np.load('Npy_data/Val_image.npy')\n","val_labels = np.load('Npy_data/Val_den.npy')\n","print('Val preparation is completed')\n","\n","# Normalized data\n","TLs_max = train_labels.max()\n","TLs_min = train_labels.min()\n","\n","train_images = (train_images - train_images.min()) / (train_images.max() - train_images.min())\n","train_labels = (train_labels - train_labels.min()) / (train_labels.max() - train_labels.min())\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["training preparation is completed\n","Val preparation is completed\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TiAC7TXGqRNy","colab_type":"text"},"source":["# Hyperparameter"]},{"cell_type":"code","metadata":{"id":"KIzkC3ptqUim","colab_type":"code","colab":{}},"source":["factor =3         # for control number of filter in the network\n","num_epoch = 50\n","batch_size = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pGSqIK1qW93","colab_type":"text"},"source":["# Slave network architecture"]},{"cell_type":"code","metadata":{"id":"MLsciUFBqcQd","colab_type":"code","outputId":"02061949-d855-4bcf-dc08-bb619c771b7f","executionInfo":{"status":"ok","timestamp":1574211816975,"user_tz":-420,"elapsed":3042,"user":{"displayName":"Sorn Sooksatra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDUB_44rDDjCoZMpsNP2bhyLr-lne4dcduqp2V75g=s64","userId":"02017460555029665816"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["x_p = tf.placeholder(shape=[None,480,640,3],dtype=tf.float32)\n","y_p = tf.placeholder(shape=[None,480,640,1],dtype=tf.float32)\n","conv_11_p = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(x_p)\n","conv_12_p = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_11_p)\n","conv_13_p = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_12_p)\n","pool_1_p  = MaxPooling2D(pool_size=(2,2))(conv_13_p)\n","\n","conv_21_p = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(pool_1_p)\n","conv_22_p = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_21_p)\n","pool_2_p  = MaxPooling2D(pool_size=(2,2))(conv_22_p)\n","\n","conv_31_p = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(pool_2_p)\n","conv_32_p = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_31_p)\n","pool_3_p  = MaxPooling2D(pool_size=(2,2))(conv_32_p)\n","\n","conv_41_p = Conv2D(64*factor, (3, 3), activation='relu', padding='same',trainable = True)(pool_3_p)\n","conv_42_p = Conv2D(64*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_41_p)\n","\n","\n","\n","up_5_p   = UpSampling2D(size = (2,2))(conv_42_p)\n","# conv_51_p = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([up_5_p, conv_32_p], axis=-1))\n","conv_51_p = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(up_5_p)\n","conv_52_p = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_51_p)\n","out_3                  = conv_52_p\n","\n","\n","up_6_p   = UpSampling2D(size = (2,2))(conv_52_p)\n","# conv_61_p = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([up_6_p, conv_22_p], axis=-1))\n","conv_61_p = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(up_6_p)\n","conv_62_p = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_61_p)\n","out_2                  = conv_62_p\n","\n","\n","up_7_p  = UpSampling2D(size = (2,2))(conv_62_p)\n","# conv_71_p = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([up_7_p, conv_13_p], axis=-1))\n","conv_71_p = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(up_7_p)\n","conv_72_p = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_71_p)\n","conv_73_p = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_72_p)\n","out_1                  = conv_73_p \n","\n","layer_final_p = Conv2D(1, (1, 1), activation='linear')(conv_73_p)\n","\n","cost_p = tf.losses.mean_squared_error(y_p,layer_final_p)\n","auto_train_p = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost_p)\n","\n","\n","# For save the model weight in each layer in the slave network\n","saver_slave=tf.train.Saver()\n","save_dir_slave = 'Save_weighted/Slave_network/'\n","if not os.path.exists(save_dir_slave):\n","    os.makedirs(save_dir_slave)\n","save_path_slave = os.path.join(save_dir_slave, 'best_validation')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"by76MFl5VkYw","colab_type":"text"},"source":["# Restore the model weights"]},{"cell_type":"code","metadata":{"id":"Q1xfwsK1Vn-1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"346a09fa-53e4-4096-d25e-e86bd2831672","executionInfo":{"status":"ok","timestamp":1574212021405,"user_tz":-420,"elapsed":16904,"user":{"displayName":"Sorn Sooksatra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDUB_44rDDjCoZMpsNP2bhyLr-lne4dcduqp2V75g=s64","userId":"02017460555029665816"}}},"source":["sess1 = tf.Session()\n","sess1.run(tf.global_variables_initializer())\n","\n","# Restore the weight\n","saver_slave.restore(sess1, \"Save_weighted/Slave_network/best_validation\")\n","print(\"Restore model successfully\")\n","\n","for current_batch_index in range(0,len(val_images),batch_size):\n","  current_batch = val_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n","  current_label = val_labels[current_batch_index:current_batch_index+batch_size,:,:,:]\n","  sess1_results = sess1.run([cost_p,out_1,out_2,out_3,layer_final_p],\n","                                      feed_dict = {x_p:current_batch,\n","                                                        y_p:current_label,\n","                                                          })\n","  P_1 = sess1_results[1]\n","  P_2 = sess1_results[2]\n","  P_3 = sess1_results[3]\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from Save_weighted/Slave_network/best_validation\n","Restore model successfully\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4JfndgEVtvpd","colab_type":"text"},"source":["# Master network architecture"]},{"cell_type":"code","metadata":{"id":"Jy9L4osouNf-","colab_type":"code","colab":{}},"source":["o1 = tf.placeholder(shape=[None,480,640,8*factor],dtype=tf.float32)\n","o2 = tf.placeholder(shape=[None,480//2,640//2,16*factor],dtype=tf.float32)\n","o3 = tf.placeholder(shape=[None,480//4,640//4,32*factor],dtype=tf.float32)\n","\n","x = tf.placeholder(shape=[None,480,640,3],dtype=tf.float32)\n","y = tf.placeholder(shape=[None,480,640,1],dtype=tf.float32)\n","conv_11 = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([o1,x],axis =-1))\n","conv_12 = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_11)\n","conv_13 = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_12)\n","# pool_1  = MaxPooling2D(pool_size=(2,2))(concatenate([o1,conv_13],axis =-1))\n","pool_1  = MaxPooling2D(pool_size=(2,2))(conv_13)\n","\n","conv_21 = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([o2,pool_1],axis =-1))\n","conv_22 = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_21)\n","# pool_2  = MaxPooling2D(pool_size=(2,2))(concatenate([o2,conv_22],axis =-1))\n","pool_2  = MaxPooling2D(pool_size=(2,2))(conv_22)\n","\n","conv_31 = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([o3,pool_2],axis =-1))\n","conv_32 = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_31)\n","# pool_3  = MaxPooling2D(pool_size=(2,2))(concatenate([o3,conv_32],axis =-1))\n","pool_3  = MaxPooling2D(pool_size=(2,2))(conv_32)\n","\n","conv_41 = Conv2D(64*factor, (3, 3), activation='relu', padding='same',trainable = True)(pool_3)\n","conv_42 = Conv2D(64*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_41)\n","\n","\n","\n","up_5   = UpSampling2D(size = (2,2))(conv_42)\n","conv_51 = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(up_5)\n","# conv_51 = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([up_5, conv_32], axis=-1))\n","conv_52 = Conv2D(32*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_51)\n","# out_3                  = conv_52\n","\n","\n","up_6   = UpSampling2D(size = (2,2))(conv_52)\n","conv_61 = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(up_6)\n","# conv_61 = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([up_6, conv_22], axis=-1))\n","conv_62 = Conv2D(16*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_61)\n","# out_2                  = conv_62\n","\n","\n","up_7   = UpSampling2D(size = (2,2))(conv_62)\n","conv_71 = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(up_7)\n","# conv_71 = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(concatenate([up_7, conv_13], axis=-1))\n","conv_72 = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_71)\n","conv_73 = Conv2D(8*factor, (3, 3), activation='relu', padding='same',trainable = True)(conv_72)\n","# out_1                  = conv_73 \n","\n","layer_final = Conv2D(1, (1, 1), activation='linear')(conv_73)\n","\n","cost = tf.losses.mean_squared_error(y,layer_final)\n","auto_train = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n","\n","\n","# For save the model weight in each layer in the master network\n","saver_master=tf.train.Saver()\n","save_dir_master = 'Save_weighted/Master_network/'\n","if not os.path.exists(save_dir_master):\n","    os.makedirs(save_dir_master)\n","save_path_master = os.path.join(save_dir_master, 'best_validation')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZQ8DdUuPuQEE","colab_type":"text"},"source":["# Restore the model weights"]},{"cell_type":"code","metadata":{"id":"rjWyTIdwuUoY","colab_type":"code","outputId":"d7facfbb-69f8-4f05-fa3d-d523a4b1d26a","executionInfo":{"status":"ok","timestamp":1574212164155,"user_tz":-420,"elapsed":5867,"user":{"displayName":"Sorn Sooksatra","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDUB_44rDDjCoZMpsNP2bhyLr-lne4dcduqp2V75g=s64","userId":"02017460555029665816"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["sess2 = tf.Session()\n","sess2.run(tf.global_variables_initializer())\n","\n","# Restore the weight\n","saver_master.restore(sess2, \"Save_weighted/Master_network/best_validation\")\n","print(\"Restore model successfully\")\n","\n","Re_matrix = np.zeros([len(val_images),2])\n","for current_batch_index in range(0,10,batch_size):\n","  current_batch = val_images[current_batch_index:current_batch_index+batch_size,:,:,:]\n","  current_label = val_labels[current_batch_index:current_batch_index+batch_size,:,:,:]\n","  sess2_results = sess2.run([cost,layer_final],\n","            feed_dict = {x:current_batch,\n","                        y:current_label,\n","                        o1:P_1,\n","                        o2:P_2,\n","                        o3:P_3\n","                        })\n","  \n","  estimated_den_map = sess2_results[1]\n","  print(current_batch_index)\n","  \n","  ### Saving in CSV file\n","  Re_num = np.sum(np.squeeze(estimated_den_map[0,:,:,0]))\n","  GT_num = np.sum(np.squeeze(current_label[0,:,:,0]))\n","  Re_matrix[current_batch_index,1] = Re_num\n","  Re_matrix[current_batch_index,0] = GT_num\n","  \n","\n","  ### For showing output\n","  show_image    = val_images[current_batch_index,:,:,:]\n","  show_den      = val_labels[current_batch_index,:,:,:]\n","  \n","  fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n","  ax1.imshow(np.squeeze(show_image))\n","  ax1.set_title('Input image')\n","\n","  ax2.imshow(np.squeeze(show_den))\n","  ax2.set_title('Ground truth')\n","\n","  ax3.imshow(np.squeeze(estimated_den_map[0,:,:,0]))\n","  ax3.set_title('estimated density map')\n","\n","  # show_index.zfill(4)\n","  plt.savefig('Output_image/Output_'+str(current_batch_index).zfill(4)+'.png')\n","\n","np.savetxt(\"Experimental_result/back_ward.csv\", Re_matrix, delimiter=\",\")\n","        "],"execution_count":14,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from Save_weighted/Master_network/best_validation\n","Restore model successfully\n","0\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["1\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["2\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["3\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["4\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["5\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["6\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["7\n","8\n"],"name":"stdout"},{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7r3ZfYeHWjc1","colab_type":"code","colab":{}},"source":["sess2_results[1]"],"execution_count":0,"outputs":[]}]}